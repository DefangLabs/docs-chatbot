services:
  app:
    restart: always
    domainname: ask.defang.io
    x-defang-dns-role: arn:aws:iam::258338292852:role/dnsadmin-39a19c3
    build:
      context: ./app
      shm_size: "16gb"
    ports:
      - target: 5050
        published: 5050
        protocol: tcp
        mode: ingress
    environment:
      ASK_TOKEN:
      FLASK_APP: app.py
      DEBUG: 0
      REBUILD_TOKEN:
      SECRET_KEY:
      SEGMENT_WRITE_KEY:
      SESSION_COOKIE_SECURE: 1
      OPENAI_API_KEY: ${OPENAI_API_KEY} # Set your OpenAI API key here or in the .env file
      OPENAI_BASE_URL: "http://llm/api/v1"
      MODEL: "anthropic.claude-3-haiku-20240307-v1:0"
      INTERCOM_TOKEN:
      INTERCOM_ADMIN_ID:
      REDIS_URL: redis://redis:6379/0
    command: uwsgi --http 0.0.0.0:5050 --wsgi-file app.py --callable app --processes 4 --threads 2
    deploy:
      resources:
        reservations:
          memory: 4G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5050/"]
      interval: 30s
      timeout: 10s
      retries: 5
      #start_period: 40s

  redis:
    image: redis:alpine
    ports:
      - target: 6379
        published: 6379
        protocol: tcp
        mode: host

  llm:
    image: defangio/openai-access-gateway
    x-defang-llm: true
    ports:
      - target: 80
        published: 80
        protocol: tcp
        mode: host
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}

  discord-bot:
    restart: unless-stopped
    build:
      context: ./discord-bot
      dockerfile: Dockerfile
      shm_size: "24gb"
    ports:
      - mode: ingress
        target: 3000
        published: 3000
    environment:
      DISCORD_APP_ID:
      DISCORD_TOKEN:
      DISCORD_PUBLIC_KEY:
      ASK_TOKEN:
    deploy:
      resources:
        reservations:
          memory: 256M
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/"]
